---
title: ç¯å¢ƒæ­å»ºæŒ‡å—
description: å¦‚ä½•é…ç½®æœ¬åœ°AIåˆ›ä½œç¯å¢ƒï¼Œä»¥åŠæ¯ä¸€æ­¥çš„æŠ€æœ¯é€‰æ‹©æ‰€å¯¹åº”çš„è§‚å¿µè€ƒé‡
---

# ç¯å¢ƒæ­å»ºæŒ‡å—

æœ¬æŒ‡å—å°†å¸®åŠ©ä½ åœ¨ä¸ªäººç”µè„‘ä¸Šæ­å»ºä¸€ä¸ªæç®€çš„ã€æœ¬åœ°è¿è¡Œçš„AIåˆ›ä½œç¯å¢ƒã€‚æ¯ä¸€æ­¥éƒ½é™„æœ‰**è§‚å¿µè€ƒé‡**ï¼Œè§£é‡Šä¸ºä»€ä¹ˆé€‰æ‹©è¿™ä¸ªå·¥å…·/é…ç½®ã€‚

## ç›®æ ‡é…ç½®

- **æ¨¡å‹è¿è¡Œæ¡†æ¶**: Ollama
- **æ¨¡å‹**: Llama 3.2 (3Bå‚æ•°ç‰ˆ) æˆ–å…¶ä»–è½»é‡çº§æ¨¡å‹
- **ç¡¬ä»¶è¦æ±‚**: 
  - æœ€ä½: 8GB RAM, ä»»æ„CPU
  - æ¨è: 16GB RAM, 8GB+ VRAMçš„GPU
- **æ“ä½œç³»ç»Ÿ**: macOS / Linux / Windows

## æ­¥éª¤1: å®‰è£… Ollama

### macOS
```bash
brew install ollama
```

### Linux
```bash
curl -fsSL https://ollama.com/install.sh | sh
```

### Windows
ä¸‹è½½å®‰è£…åŒ…: https://ollama.com/download

### ğŸ’¡ è§‚å¿µè€ƒé‡

**ä¸ºä»€ä¹ˆé€‰æ‹© Ollamaï¼Ÿ**
- **æç®€**: ä¸€æ¡å‘½ä»¤å®‰è£…ï¼Œæ— éœ€å¤æ‚é…ç½®
- **æœ¬åœ°**: æ‰€æœ‰è¿ç®—åœ¨æœ¬åœ°å®Œæˆï¼Œæ•°æ®ä¸ä¸Šä¼ 
- **å¼€æº**: åŸºäºå¼€æºé¡¹ç›®ï¼Œå¯å®¡è®¡
- **è½»é‡**: ä¸“ä¸ºæ¶ˆè´¹çº§ç¡¬ä»¶ä¼˜åŒ–

**å¯¹æ¯”äº‘ç«¯æœåŠ¡ (ChatGPT/Claude)**:
| ç»´åº¦ | äº‘ç«¯ | Ollamaæœ¬åœ° |
|------|------|-----------|
| éšç§ | æ•°æ®ä¸Šä¼  | å®Œå…¨æœ¬åœ° |
| æ§åˆ¶ | é»‘ç®± | å¯é…ç½® |
| ä¾èµ– | éœ€è¦ç½‘ç»œ | ç¦»çº¿å¯ç”¨ |
| æˆæœ¬ | è®¢é˜…è´¹ | ç”µè´¹ |
| é€Ÿåº¦ | å¿« | è¾ƒæ…¢ï¼ˆä½†å¯æ„ŸçŸ¥ï¼‰|

## æ­¥éª¤2: ä¸‹è½½æ¨¡å‹

```bash
# æ¨èï¼šLlama 3.2 (3Bå‚æ•°ï¼Œè½»é‡ä½†èƒ½åŠ›å¼º)
ollama pull llama3.2:3b

# å¤‡é€‰ï¼šMistral (7Bå‚æ•°ï¼Œè´¨é‡æ›´é«˜ä½†éœ€è¦æ›´å¤šèµ„æº)
ollama pull mistral:7b

# å¤‡é€‰ï¼šPhi-3 (Microsoftçš„å°æ¨¡å‹ï¼Œ3.8Bå‚æ•°)
ollama pull phi3:3.8b
```

### ğŸ’¡ è§‚å¿µè€ƒé‡

**ä¸ºä»€ä¹ˆé€‰æ‹©"å°æ¨¡å‹"ï¼Ÿ**

1. **ç‰©è´¨æ€§å¯è§**: å°æ¨¡å‹åœ¨æœ¬åœ°è¿è¡Œæ—¶ï¼Œä½ èƒ½**æ„ŸçŸ¥åˆ°**ç¡¬ä»¶çš„é™åˆ¶â€”â€”é£æ‰‡è½¬åŠ¨ã€å“åº”å»¶è¿Ÿã€‚è¿™ç§"ç¬¨æ‹™"æ˜¯åˆ›ä½œä½“éªŒçš„ä¸€éƒ¨åˆ†ã€‚

2. **çº¦æŸå³åˆ›ä½œ**: å°æ¨¡å‹çš„"èƒ½åŠ›ä¸è¶³"è¿«ä½¿ä½ è°ƒæ•´æç¤ºç­–ç•¥ï¼Œè¿™ç§è°ƒæ•´æœ¬èº«å°±æ˜¯åˆ›ä½œã€‚

3. **å»ä¸­å¿ƒåŒ–**: ä¸ä¾èµ–ç§‘æŠ€å·¨å¤´çš„APIï¼Œç»´æŠ¤åˆ›ä½œçš„ç‹¬ç«‹æ€§ã€‚

**æ¨¡å‹é€‰æ‹©å»ºè®®**:
- **åˆå­¦è€…**: llama3.2:3bï¼ˆå¹³è¡¡æ€§èƒ½ä¸èµ„æºï¼‰
- **è¿½æ±‚è´¨é‡**: mistral:7bï¼ˆéœ€è¦8GB+ VRAMï¼‰
- **æç®€ä¸»ä¹‰**: phi3:3.8bï¼ˆæœ€å°èµ„æºå ç”¨ï¼‰

## æ­¥éª¤3: æµ‹è¯•è¿è¡Œ

```bash
# å¯åŠ¨äº¤äº’å¼ä¼šè¯
ollama run llama3.2:3b
```

ä½ ä¼šçœ‹åˆ°ç±»ä¼¼ï¼š
```
>>> ä½ å¥½
ä½ å¥½ï¼æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ
```

è¾“å…¥ `/bye` é€€å‡ºã€‚

### ğŸ’¡ è§‚å¿µè€ƒé‡

**å‘½ä»¤è¡Œç•Œé¢çš„ä»·å€¼**

ä¸ChatGPTçš„å›¾å½¢ç•Œé¢ç›¸æ¯”ï¼Œå‘½ä»¤è¡Œï¼š
- **æ›´æ…¢**: æ²¡æœ‰è‡ªåŠ¨è¡¥å…¨ï¼Œæ¯æ¬¡è¾“å…¥éƒ½æ˜¯å®Œæ•´çš„æ€è€ƒ
- **æ›´å¯è§**: å†å²è®°å½•ä¿å­˜åœ¨æœ¬åœ°æ–‡ä»¶ä¸­
- **æ›´ç¬¨æ‹™**: è¿™ç§"ä¸é¡ºç•…"è¿«ä½¿ä½ æ›´å®¡æ…åœ°è¡¨è¾¾

## æ­¥éª¤4: é…ç½®æ—¥å¿—è®°å½•ï¼ˆå¯é€‰ä½†æ¨èï¼‰

åˆ›å»ºä¸€ä¸ªè„šæœ¬ `chat.sh`ï¼š

```bash
#!/bin/bash
TIMESTAMP=$(date +%Y%m%d_%H%M%S)
LOGFILE="logs/session_$TIMESTAMP.log"

mkdir -p logs
echo "=== Session started at $(date) ===" > $LOGFILE
echo "Model: llama3.2:3b" >> $LOGFILE
echo "================================" >> $LOGFILE

ollama run llama3.2:3b | tee -a $LOGFILE
```

èµ‹äºˆæ‰§è¡Œæƒé™ï¼š
```bash
chmod +x chat.sh
```

### ğŸ’¡ è§‚å¿µè€ƒé‡

**ä¸ºä»€ä¹ˆè®°å½•æ—¥å¿—ï¼Ÿ**

æ—¥å¿—æ˜¯[è¿‡ç¨‹æ˜¾å½¢](../theory/process-visibilization.md)çš„åŸºç¡€ææ–™ã€‚å®ƒè®°å½•äº†ï¼š
- æ—¶é—´æµé€ï¼ˆåˆ›ä½œä¸æ˜¯ç¬æ—¶çš„ï¼‰
- å†³ç­–åºåˆ—ï¼ˆä½ å¦‚ä½•è°ƒæ•´æç¤ºï¼‰
- æŠ€æœ¯ç—•è¿¹ï¼ˆå»¶è¿Ÿã€é”™è¯¯ã€ç³»ç»ŸçŠ¶æ€ï¼‰

## ä¸‹ä¸€æ­¥

ç¯å¢ƒæ­å»ºå®Œæˆåï¼Œä½ å¯ä»¥ï¼š

1. **é˜…è¯» [çº¦æŸè®¾è®¡æ¨¡å¼](constraint-patterns.md)** â€” å­¦ä¹ å…·ä½“çš„çº¦æŸç­–ç•¥
2. **å®‰è£… constraint-cli** â€” ä½¿ç”¨æˆ‘ä»¬çš„ç ”ç©¶å·¥å…·
3. **å¼€å§‹ç¬¬ä¸€æ¬¡å®è·µ** â€” å°è¯•ç”¨çº¦æŸæ¡ä»¶ä¸AIå¯¹è¯

## æ•…éšœæ’é™¤

### æ¨¡å‹ä¸‹è½½æ…¢
```bash
# è®¾ç½®é•œåƒï¼ˆä¸­å›½ç”¨æˆ·ï¼‰
export OLLAMA_HOST=0.0.0.0
# æˆ–ä½¿ç”¨ä»£ç†
```

### å†…å­˜ä¸è¶³
```bash
# ä½¿ç”¨æ›´å°çš„æ¨¡å‹
ollama pull llama3.2:1b
```

### GPUæœªè¯†åˆ«
```bash
# æ£€æŸ¥CUDA/Metalæ”¯æŒ
ollama --version
# æŸ¥çœ‹æ—¥å¿—
ollama serve 2>&1 | grep -i gpu
```

## å»¶ä¼¸é˜…è¯»

- [æœ¬åœ°æ€§](../theory/locality.md) â€” æœ¬åœ°è¿ç®—çš„ç†è®ºåŸºç¡€
- [å°æ¨¡å‹](../theory/small-models.md) â€” è½»é‡çº§æ¨¡å‹çš„ç¾å­¦æ„æ¶µ
- Ollama å®˜æ–¹æ–‡æ¡£: https://github.com/ollama/ollama
